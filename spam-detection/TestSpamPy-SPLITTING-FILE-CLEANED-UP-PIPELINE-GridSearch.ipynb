{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, classification_report, accuracy_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_overall_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file_name = './SpamDetectionData.txt'\n",
    "    rawdata = open(file_name, 'r')\n",
    "    lines = rawdata.readlines()\n",
    "    lines = lines[1:] #get rid of \"header\"\n",
    "    spam_train = lines[0:1000]\n",
    "    ham_train = lines[1002:2002]\n",
    "    test_mix = lines[2004:]\n",
    "    return (spam_train, ham_train, test_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train, ham_train, test_mix = get_data()\n",
    "\n",
    "precent = 1.0 #0.0035\n",
    "count = int(len(ham_train) * precent)\n",
    "train_data = spam_train + ham_train[0:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(input_array):    \n",
    "    spam_indcator = 'Spam,<p>'\n",
    "    message_class = np.array([1 if spam_indcator in item else 0 for item in input_array])\n",
    "    data = pd.DataFrame()\n",
    "    data['class'] = message_class\n",
    "    data['message'] = input_array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = create_dataframe(train_data)\n",
    "df_test = create_dataframe(test_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ham,&lt;p&gt;Bust by this expressing at stepped and....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ham,&lt;p&gt;Again on quaff nothing. It explore stoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ham,&lt;p&gt;Tell floor perched. Doubting curious of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ham,&lt;p&gt;Angels nameless caught thrilled mefille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Spam,&lt;p&gt;So his chaste my. Mote way fabled as o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                            message\n",
       "0      0  Ham,<p>Bust by this expressing at stepped and....\n",
       "1      0  Ham,<p>Again on quaff nothing. It explore stoo...\n",
       "2      0  Ham,<p>Tell floor perched. Doubting curious of...\n",
       "3      0  Ham,<p>Angels nameless caught thrilled mefille...\n",
       "4      1  Spam,<p>So his chaste my. Mote way fabled as o..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_remove = ['Ham,<p>', 'Spam,<p>', '<p>', '</p>', '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_words(input_line, key_words=words_to_remove):\n",
    "    temp = input_line\n",
    "    for word in key_words:\n",
    "        temp = temp.replace(word, '')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_words_and_shuffle(input_dataframe, input_random_state=7):\n",
    "    input_dataframe['message'] = input_dataframe['message'].apply(remove_words)\n",
    "    messages, classes = shuffle(input_dataframe['message'], input_dataframe['class'], random_state=input_random_state)\n",
    "    df_return = pd.DataFrame()\n",
    "    df_return['class'] = classes\n",
    "    df_return['message'] = messages\n",
    "    return df_return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_cleaned = remove_words_and_shuffle(df_train)\n",
    "df_test_cleaned = remove_words_and_shuffle(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_raw = df_train_cleaned['message']\n",
    "y_train = df_train_cleaned['class']\n",
    "\n",
    "X_test_raw = df_test_cleaned['message']\n",
    "y_test = df_test_cleaned['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_accuracy(actual_y, predicted_y, model_name, train_time, predict_time):\n",
    "    print('Model Name: ' + model_name)\n",
    "    print('Train time: ', round(train_time, 2))\n",
    "    print('Predict time: ', round(predict_time, 2))\n",
    "    print('Model Accuracy: {:.4f}'.format(accuracy_score(actual_y, predicted_y)))\n",
    "    print('Model Precision: {:.4f}'.format(precision_score(actual_y, predicted_y)))\n",
    "    print('')\n",
    "    print(classification_report(actual_y, predicted_y, digits=4))\n",
    "    print(\"=========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_models(X_train_input_raw, y_train_input, X_test_input_raw, y_test_input, models_dict):\n",
    "\n",
    "    return_trained_models = {}\n",
    "    \n",
    "    return_vectorizer = FeatureUnion([('count_vect', CountVectorizer()), ('tfidf_vect', TfidfVectorizer())])\n",
    "    \n",
    "    X_train = return_vectorizer.fit_transform(X_train_input_raw)\n",
    "    X_test = return_vectorizer.transform(X_test_input_raw)\n",
    "    \n",
    "    for key in models_dict:\n",
    "        model_name = key\n",
    "        model = models_dict[key]\n",
    "        t1 = time.time()\n",
    "        model.fit(X_train, y_train_input)\n",
    "        t2 = time.time()\n",
    "        predicted_y = model.predict(X_test)\n",
    "        t3 = time.time()\n",
    "        \n",
    "        output_accuracy(y_test_input, predicted_y, model_name, t2 - t1, t3 - t2)        \n",
    "        return_trained_models[model_name] = model\n",
    "        \n",
    "    return (return_trained_models, return_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    models = {}\n",
    "    models['LinearSVC'] = LinearSVC()\n",
    "    models['LogisticRegression'] = LogisticRegression()\n",
    "    models['RandomForestClassifier'] = RandomForestClassifier()\n",
    "    models['DecisionTreeClassifier'] = DecisionTreeClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: LogisticRegression\n",
      "Train time:  0.09\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "=========================================================================\n",
      "Model Name: LinearSVC\n",
      "Train time:  0.03\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "=========================================================================\n",
      "Model Name: RandomForestClassifier\n",
      "Train time:  0.06\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "=========================================================================\n",
      "Model Name: DecisionTreeClassifier\n",
      "Train time:  0.11\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "models = create_models()\n",
    "trained_models, fitted_vectorizer = test_models(X_train_raw, y_train, X_test_raw, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_overall_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall time:  2.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall time: \", round(stop_overall_time - start_overall_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = df_test[1:2]\n",
    "test_msg = row['message']\n",
    "test_class = row['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Again on quaff nothing. It explore stood usby ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_msg = ['this is my test message']\n",
    "transformed_test_msg = fitted_vectorizer.transform(test_msg)\n",
    "prediction = trained_models['DecisionTreeClassifier'].predict(transformed_test_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import out grid search module\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model, # the model to grid search\n",
    "                        params, # the parameter set to try \n",
    "                        error_score=0.) # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "    grid.fit(X, y) # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print(\"Best Accuracy: {}\".format(grid.best_score_))\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    print(\"Average Time to Fit (s): {}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n",
    "    # the average time it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print(\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = [0, 1,2,3,4,5]\n",
    "j[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bust by this expressing at stepped and. My my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Again on quaff nothing. It explore stood usby ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tell floor perched. Doubting curious of only b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Angels nameless caught thrilled mefilled. Till...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>So his chaste my. Mote way fabled as of aye fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                            message\n",
       "0      0  Bust by this expressing at stepped and. My my ...\n",
       "1      0  Again on quaff nothing. It explore stood usby ...\n",
       "2      0  Tell floor perched. Doubting curious of only b...\n",
       "3      0  Angels nameless caught thrilled mefilled. Till...\n",
       "4      1  So his chaste my. Mote way fabled as of aye fr..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam,<p>But could then once pomp to nor that glee glorious of deigned. The vexed times childe none native. To he vast now in to sore nor flow and most fabled. The few tis to loved vexed and all yet yea childe. Fulness consecrate of it before his a a a that.</p><p>Mirthful and and pangs wrong. Objects isle with partings ancient made was are. Childe and gild of all had to and ofttimes made soon from to long youth way condole sore.</p>\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from the sample ham and spam\n",
    "ham = 'door beguiling cushions did. Evermore from raven from is beak shall name'\n",
    "spam = 'The vexed times childe none native'\n",
    "test_messages = [spam, ham]\n",
    "transformed_test_messages = fitted_vectorizer.transform(test_messages)\n",
    "trained_models['DecisionTreeClassifier'].predict(transformed_test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
