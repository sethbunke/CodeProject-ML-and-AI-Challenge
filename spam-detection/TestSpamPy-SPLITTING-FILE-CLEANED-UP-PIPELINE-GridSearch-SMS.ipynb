{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, classification_report, accuracy_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_overall_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    file_name = './SpamDetectionData.txt'\n",
    "    rawdata = open(file_name, 'r')\n",
    "    lines = rawdata.readlines()\n",
    "    lines = lines[1:] #get rid of \"header\"\n",
    "    spam_train = lines[0:1000]\n",
    "    ham_train = lines[1002:2002]\n",
    "    test_mix = lines[2004:]\n",
    "    return (spam_train, ham_train, test_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train, ham_train, test_mix = get_data()\n",
    "\n",
    "precent = 0.0035 #1.0 #0.0035\n",
    "count = int(len(ham_train) * precent)\n",
    "train_data = spam_train + ham_train[0:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(input_array):    \n",
    "    spam_indcator = 'Spam,<p>'\n",
    "    message_class = np.array([1 if spam_indcator in item else 0 for item in input_array])\n",
    "    data = pd.DataFrame()\n",
    "    data['class'] = message_class\n",
    "    data['message'] = input_array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = create_dataframe(train_data)\n",
    "df_test = create_dataframe(test_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_remove = ['Ham,<p>', 'Spam,<p>', '<p>', '</p>', '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_words(input_line, key_words=words_to_remove):\n",
    "    temp = input_line\n",
    "    for word in key_words:\n",
    "        temp = temp.replace(word, '')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_words_and_shuffle(input_dataframe, input_random_state=7):\n",
    "    input_dataframe['message'] = input_dataframe['message'].apply(remove_words)\n",
    "    messages, classes = shuffle(input_dataframe['message'], input_dataframe['class'], random_state=input_random_state)\n",
    "    df_return = pd.DataFrame()\n",
    "    df_return['class'] = classes\n",
    "    df_return['message'] = messages\n",
    "    return df_return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_cleaned = remove_words_and_shuffle(df_train)\n",
    "df_test_cleaned = remove_words_and_shuffle(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_raw = df_train_cleaned['message']\n",
    "y_train = df_train_cleaned['class']\n",
    "\n",
    "X_test_raw = df_test_cleaned['message']\n",
    "y_test = df_test_cleaned['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_accuracy(actual_y, predicted_y, model_name, train_time, predict_time):\n",
    "    print('Model Name: ' + model_name)\n",
    "    print('Train time: ', round(train_time, 2))\n",
    "    print('Predict time: ', round(predict_time, 2))\n",
    "    print('Model Accuracy: {:.4f}'.format(accuracy_score(actual_y, predicted_y)))\n",
    "    print('Model Precision: {:.4f}'.format(precision_score(actual_y, predicted_y)))\n",
    "    print('')\n",
    "    print(classification_report(actual_y, predicted_y, digits=4))\n",
    "    print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_models(X_train_input_raw, y_train_input, X_test_input_raw, y_test_input, models_dict):\n",
    "\n",
    "    return_trained_models = {}\n",
    "    \n",
    "    #return_vectorizer = FeatureUnion([('count_vect', CountVectorizer()), ('tfidf_vect', TfidfVectorizer())])\n",
    "    return_vectorizer = FeatureUnion([('tfidf_vect', TfidfVectorizer())])\n",
    "    \n",
    "    X_train = return_vectorizer.fit_transform(X_train_input_raw)\n",
    "    X_test = return_vectorizer.transform(X_test_input_raw)\n",
    "    \n",
    "    for key in models_dict:\n",
    "        model_name = key\n",
    "        model = models_dict[key]\n",
    "        t1 = time.time()\n",
    "        model.fit(X_train, y_train_input)\n",
    "        t2 = time.time()\n",
    "        predicted_y = model.predict(X_test)\n",
    "        t3 = time.time()\n",
    "        \n",
    "        output_accuracy(y_test_input, predicted_y, model_name, t2 - t1, t3 - t2)        \n",
    "        return_trained_models[model_name] = model\n",
    "        \n",
    "    return (return_trained_models, return_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    models = {}\n",
    "    models['LinearSVC'] = LinearSVC()\n",
    "    models['LogisticRegression'] = LogisticRegression()\n",
    "    models['RandomForestClassifier'] = RandomForestClassifier()\n",
    "    models['DecisionTreeClassifier'] = DecisionTreeClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: LinearSVC\n",
      "Train time:  0.01\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "======================================================\n",
      "Model Name: LogisticRegression\n",
      "Train time:  0.01\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.4300\n",
      "Model Precision: 0.4300\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.0000    0.0000    0.0000        57\n",
      "          1     0.4300    1.0000    0.6014        43\n",
      "\n",
      "avg / total     0.1849    0.4300    0.2586       100\n",
      "\n",
      "======================================================\n",
      "Model Name: DecisionTreeClassifier\n",
      "Train time:  0.02\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.9800\n",
      "Model Precision: 0.9556\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.9649    0.9821        57\n",
      "          1     0.9556    1.0000    0.9773        43\n",
      "\n",
      "avg / total     0.9809    0.9800    0.9800       100\n",
      "\n",
      "======================================================\n",
      "Model Name: RandomForestClassifier\n",
      "Train time:  0.02\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.9800\n",
      "Model Precision: 0.9556\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.9649    0.9821        57\n",
      "          1     0.9556    1.0000    0.9773        43\n",
      "\n",
      "avg / total     0.9809    0.9800    0.9800       100\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth.bunke/anaconda/envs/Python3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "models = create_models()\n",
    "trained_models, fitted_vectorizer = test_models(X_train_raw, y_train, X_test_raw, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_overall_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall time:  0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall time: \", round(stop_overall_time - start_overall_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = df_test[1:2]\n",
    "test_msg = row['message']\n",
    "test_class = row['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Again on quaff nothing. It explore stood usby ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_msg = ['this is my test message']\n",
    "transformed_test_msg = fitted_vectorizer.transform(test_msg)\n",
    "prediction = trained_models['DecisionTreeClassifier'].predict(transformed_test_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import out grid search module\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model, # the model to grid search\n",
    "                        params, # the parameter set to try \n",
    "                        error_score=0.) # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "    grid.fit(X, y) # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print(\"Best Accuracy: {}\".format(grid.best_score_))\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    print(\"Average Time to Fit (s): {}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n",
    "    # the average time it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print(\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = [0, 1,2,3,4,5]\n",
    "j[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "\n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        #index.append(filename)\n",
    "\n",
    "    return DataFrame(rows) #, index=index)\n",
    "\n",
    "data = DataFrame({'message': [], 'class': []})\n",
    "\n",
    "data = data.append(dataFrameFromDirectory('./emails/spam', 'spam'))\n",
    "data = data.append(dataFrameFromDirectory('./emails/ham', 'ham'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam = data[data['class'] == 'spam']['message']\n",
    "ham = data[data['class'] == 'ham']['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spam_msg = spam['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxx = ['this is my test','my test','hey there']\n",
    "transformed_test_xxxx = fitted_vectorizer.transform(xxx)\n",
    "prediction_xxx = trained_models['DecisionTreeClassifier'].predict(transformed_test_xxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prediction_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_test_ham = fitted_vectorizer.transform(ham)\n",
    "prediction_ham = trained_models['DecisionTreeClassifier'].predict(transformed_test_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_test_spam = fitted_vectorizer.transform(ham)\n",
    "prediction_spam = trained_models['DecisionTreeClassifier'].predict(transformed_test_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Date:        Wed, 21 Aug 2002 10:54:46 -05...\n",
       "1    Martin A posted:\\n\\nTassos Papadopoulos, the G...\n",
       "2    Man Threatens Explosion In Moscow \\n\\n\\n\\nThur...\n",
       "3    Klez: The Virus That Won't Die\\n\\n \\n\\nAlready...\n",
       "4    >  in adding cream to spaghetti carbonara, whi...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ham_zeros = np.zeros(len(prediction_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_ones = np.ones(len(prediction_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_actual_results = []\n",
    "all_actual_results.extend(ham_zeros)\n",
    "all_actual_results.extend(spam_ones) \n",
    "\n",
    "all_predict_results = []\n",
    "all_predict_results.extend(prediction_spam)\n",
    "all_predict_results.extend(prediction_ham) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_actual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: my name\n",
      "Train time:  0.0\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.5000\n",
      "Model Precision: 0.5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.5000    0.0012    0.0024      2500\n",
      "        1.0     0.5000    0.9988    0.6664      2500\n",
      "\n",
      "avg / total     0.5000    0.5000    0.3344      5000\n",
      "\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "output_accuracy(all_actual_results, all_predict_results, 'my name', time.time() - time.time(), time.time() - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: LinearSVC\n",
      "Train time:  0.0\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 1.0000\n",
      "Model Precision: 1.0000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    1.0000    1.0000        57\n",
      "          1     1.0000    1.0000    1.0000        43\n",
      "\n",
      "avg / total     1.0000    1.0000    1.0000       100\n",
      "\n",
      "======================================================\n",
      "Model Name: LogisticRegression\n",
      "Train time:  0.01\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.4300\n",
      "Model Precision: 0.4300\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.0000    0.0000    0.0000        57\n",
      "          1     0.4300    1.0000    0.6014        43\n",
      "\n",
      "avg / total     0.1849    0.4300    0.2586       100\n",
      "\n",
      "======================================================\n",
      "Model Name: DecisionTreeClassifier\n",
      "Train time:  0.02\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.9200\n",
      "Model Precision: 0.8431\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.8596    0.9245        57\n",
      "          1     0.8431    1.0000    0.9149        43\n",
      "\n",
      "avg / total     0.9325    0.9200    0.9204       100\n",
      "\n",
      "======================================================\n",
      "Model Name: RandomForestClassifier\n",
      "Train time:  0.02\n",
      "Predict time:  0.0\n",
      "Model Accuracy: 0.9800\n",
      "Model Precision: 0.9556\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.9649    0.9821        57\n",
      "          1     0.9556    1.0000    0.9773        43\n",
      "\n",
      "avg / total     0.9809    0.9800    0.9800       100\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seth.bunke/anaconda/envs/Python3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "models = create_models()\n",
    "trained_models, fitted_vectorizer = test_models(X_train_raw, y_train, X_test_raw, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = ['free viagra','this is my test message']\n",
    "transformed_samples = fitted_vectorizer.transform(samples)\n",
    "trained_models['DecisionTreeClassifier'].predict(transformed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
